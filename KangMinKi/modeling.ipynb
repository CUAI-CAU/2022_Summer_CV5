{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Keras \n",
    "- using nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"result/features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_hip_anlge</th>\n",
       "      <th>right_hip_anlge</th>\n",
       "      <th>left_knee_anlge</th>\n",
       "      <th>right_knee_anlge</th>\n",
       "      <th>left_ankle_angle_1</th>\n",
       "      <th>left_ankle_angle_2</th>\n",
       "      <th>right_ankle_angle_1</th>\n",
       "      <th>right_ankle_angle_2</th>\n",
       "      <th>hip_x_diff</th>\n",
       "      <th>hip_y_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>heel_depth_diff</th>\n",
       "      <th>footindex_x_diff</th>\n",
       "      <th>footindex_y_diff</th>\n",
       "      <th>footindex_depth_diff</th>\n",
       "      <th>hip_length</th>\n",
       "      <th>knee_length</th>\n",
       "      <th>ankle_length</th>\n",
       "      <th>heel_length</th>\n",
       "      <th>footindex_length</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152.990016</td>\n",
       "      <td>143.001878</td>\n",
       "      <td>-175.706858</td>\n",
       "      <td>-167.176073</td>\n",
       "      <td>124.687808</td>\n",
       "      <td>124.687808</td>\n",
       "      <td>117.753249</td>\n",
       "      <td>178.871808</td>\n",
       "      <td>-0.022037</td>\n",
       "      <td>-0.010157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209389</td>\n",
       "      <td>-0.005688</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>-0.246590</td>\n",
       "      <td>0.024265</td>\n",
       "      <td>0.029204</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153.089893</td>\n",
       "      <td>143.214624</td>\n",
       "      <td>-176.153893</td>\n",
       "      <td>-167.000301</td>\n",
       "      <td>125.901900</td>\n",
       "      <td>125.901900</td>\n",
       "      <td>119.170554</td>\n",
       "      <td>178.859718</td>\n",
       "      <td>-0.021962</td>\n",
       "      <td>-0.010169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209575</td>\n",
       "      <td>-0.010760</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.246531</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.029707</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0.029309</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153.313472</td>\n",
       "      <td>143.486636</td>\n",
       "      <td>-175.592888</td>\n",
       "      <td>-166.703123</td>\n",
       "      <td>125.525454</td>\n",
       "      <td>125.525454</td>\n",
       "      <td>120.885401</td>\n",
       "      <td>179.617597</td>\n",
       "      <td>-0.021918</td>\n",
       "      <td>-0.010162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210042</td>\n",
       "      <td>-0.014307</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>-0.247234</td>\n",
       "      <td>0.024160</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>0.031547</td>\n",
       "      <td>0.028907</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153.397308</td>\n",
       "      <td>143.567509</td>\n",
       "      <td>-175.258291</td>\n",
       "      <td>-166.461172</td>\n",
       "      <td>125.352400</td>\n",
       "      <td>125.352400</td>\n",
       "      <td>120.464476</td>\n",
       "      <td>179.698710</td>\n",
       "      <td>-0.021915</td>\n",
       "      <td>-0.010131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209887</td>\n",
       "      <td>-0.013344</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>-0.247226</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>0.030935</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153.443670</td>\n",
       "      <td>143.492207</td>\n",
       "      <td>-174.962993</td>\n",
       "      <td>-166.405916</td>\n",
       "      <td>124.336604</td>\n",
       "      <td>124.336604</td>\n",
       "      <td>119.684258</td>\n",
       "      <td>179.568240</td>\n",
       "      <td>-0.021736</td>\n",
       "      <td>-0.010054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209237</td>\n",
       "      <td>-0.011709</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>-0.247245</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>0.034196</td>\n",
       "      <td>0.030836</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135605</th>\n",
       "      <td>-172.103115</td>\n",
       "      <td>-178.989007</td>\n",
       "      <td>151.224142</td>\n",
       "      <td>164.686950</td>\n",
       "      <td>-119.294532</td>\n",
       "      <td>-119.294532</td>\n",
       "      <td>-109.548147</td>\n",
       "      <td>-169.571432</td>\n",
       "      <td>-0.091402</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241113</td>\n",
       "      <td>-0.046102</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>0.265046</td>\n",
       "      <td>0.091595</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.016802</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>0.052844</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135606</th>\n",
       "      <td>-171.450864</td>\n",
       "      <td>-178.724279</td>\n",
       "      <td>153.743514</td>\n",
       "      <td>166.360879</td>\n",
       "      <td>-116.781227</td>\n",
       "      <td>-116.781227</td>\n",
       "      <td>-111.486480</td>\n",
       "      <td>-169.417255</td>\n",
       "      <td>-0.090995</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245908</td>\n",
       "      <td>-0.024700</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.271999</td>\n",
       "      <td>0.091194</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.031789</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135607</th>\n",
       "      <td>-170.175042</td>\n",
       "      <td>-179.811477</td>\n",
       "      <td>158.854289</td>\n",
       "      <td>171.105270</td>\n",
       "      <td>-115.371234</td>\n",
       "      <td>-115.371234</td>\n",
       "      <td>-112.017345</td>\n",
       "      <td>-171.917360</td>\n",
       "      <td>-0.079152</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248112</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>0.021912</td>\n",
       "      <td>0.273472</td>\n",
       "      <td>0.079391</td>\n",
       "      <td>0.030440</td>\n",
       "      <td>0.053772</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135608</th>\n",
       "      <td>-170.287840</td>\n",
       "      <td>179.997941</td>\n",
       "      <td>158.786340</td>\n",
       "      <td>171.833840</td>\n",
       "      <td>-112.702916</td>\n",
       "      <td>-112.702916</td>\n",
       "      <td>-111.178383</td>\n",
       "      <td>-171.181592</td>\n",
       "      <td>-0.077574</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240782</td>\n",
       "      <td>0.028780</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>0.266361</td>\n",
       "      <td>0.077833</td>\n",
       "      <td>0.031844</td>\n",
       "      <td>0.049678</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>0.036268</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135609</th>\n",
       "      <td>-166.008801</td>\n",
       "      <td>-179.520176</td>\n",
       "      <td>161.389140</td>\n",
       "      <td>171.503279</td>\n",
       "      <td>-118.268117</td>\n",
       "      <td>-118.268117</td>\n",
       "      <td>-111.726932</td>\n",
       "      <td>-170.416124</td>\n",
       "      <td>-0.072327</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249770</td>\n",
       "      <td>0.109860</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.275109</td>\n",
       "      <td>0.072610</td>\n",
       "      <td>0.063430</td>\n",
       "      <td>0.127003</td>\n",
       "      <td>0.125666</td>\n",
       "      <td>0.111881</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135610 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        left_hip_anlge  right_hip_anlge  left_knee_anlge  right_knee_anlge  \\\n",
       "0           152.990016       143.001878      -175.706858       -167.176073   \n",
       "1           153.089893       143.214624      -176.153893       -167.000301   \n",
       "2           153.313472       143.486636      -175.592888       -166.703123   \n",
       "3           153.397308       143.567509      -175.258291       -166.461172   \n",
       "4           153.443670       143.492207      -174.962993       -166.405916   \n",
       "...                ...              ...              ...               ...   \n",
       "135605     -172.103115      -178.989007       151.224142        164.686950   \n",
       "135606     -171.450864      -178.724279       153.743514        166.360879   \n",
       "135607     -170.175042      -179.811477       158.854289        171.105270   \n",
       "135608     -170.287840       179.997941       158.786340        171.833840   \n",
       "135609     -166.008801      -179.520176       161.389140        171.503279   \n",
       "\n",
       "        left_ankle_angle_1  left_ankle_angle_2  right_ankle_angle_1  \\\n",
       "0               124.687808          124.687808           117.753249   \n",
       "1               125.901900          125.901900           119.170554   \n",
       "2               125.525454          125.525454           120.885401   \n",
       "3               125.352400          125.352400           120.464476   \n",
       "4               124.336604          124.336604           119.684258   \n",
       "...                    ...                 ...                  ...   \n",
       "135605         -119.294532         -119.294532          -109.548147   \n",
       "135606         -116.781227         -116.781227          -111.486480   \n",
       "135607         -115.371234         -115.371234          -112.017345   \n",
       "135608         -112.702916         -112.702916          -111.178383   \n",
       "135609         -118.268117         -118.268117          -111.726932   \n",
       "\n",
       "        right_ankle_angle_2  hip_x_diff  hip_y_diff  ...  heel_depth_diff  \\\n",
       "0                178.871808   -0.022037   -0.010157  ...        -0.209389   \n",
       "1                178.859718   -0.021962   -0.010169  ...        -0.209575   \n",
       "2                179.617597   -0.021918   -0.010162  ...        -0.210042   \n",
       "3                179.698710   -0.021915   -0.010131  ...        -0.209887   \n",
       "4                179.568240   -0.021736   -0.010054  ...        -0.209237   \n",
       "...                     ...         ...         ...  ...              ...   \n",
       "135605          -169.571432   -0.091402    0.005945  ...         0.241113   \n",
       "135606          -169.417255   -0.090995    0.006019  ...         0.245908   \n",
       "135607          -171.917360   -0.079152    0.006154  ...         0.248112   \n",
       "135608          -171.181592   -0.077574    0.006344  ...         0.240782   \n",
       "135609          -170.416124   -0.072327    0.006402  ...         0.249770   \n",
       "\n",
       "        footindex_x_diff  footindex_y_diff  footindex_depth_diff  hip_length  \\\n",
       "0              -0.005688          0.002777             -0.246590    0.024265   \n",
       "1              -0.010760          0.003125             -0.246531    0.024202   \n",
       "2              -0.014307          0.003023             -0.247234    0.024160   \n",
       "3              -0.013344          0.004727             -0.247226    0.024143   \n",
       "4              -0.011709          0.004902             -0.247245    0.023949   \n",
       "...                  ...               ...                   ...         ...   \n",
       "135605         -0.046102          0.025827              0.265046    0.091595   \n",
       "135606         -0.024700          0.020011              0.271999    0.091194   \n",
       "135607          0.031073          0.021912              0.273472    0.079391   \n",
       "135608          0.028780          0.022070              0.266361    0.077833   \n",
       "135609          0.109860          0.021170              0.275109    0.072610   \n",
       "\n",
       "        knee_length  ankle_length  heel_length  footindex_length  class  \n",
       "0          0.029204      0.031500     0.028015          0.006329      0  \n",
       "1          0.029707      0.031654     0.029309          0.011205      0  \n",
       "2          0.029508      0.031547     0.028907          0.014623      0  \n",
       "3          0.029883      0.033603     0.030935          0.014157      0  \n",
       "4          0.030548      0.034196     0.030836          0.012693      0  \n",
       "...             ...           ...          ...               ...    ...  \n",
       "135605     0.009056      0.016802     0.024268          0.052844      6  \n",
       "135606     0.007935      0.008990     0.012116          0.031789      6  \n",
       "135607     0.030440      0.053772     0.049270          0.038022      6  \n",
       "135608     0.031844      0.049678     0.045033          0.036268      6  \n",
       "135609     0.063430      0.127003     0.125666          0.111881      6  \n",
       "\n",
       "[135610 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_hip_anlge          9\n",
       "right_hip_anlge         9\n",
       "left_knee_anlge         9\n",
       "right_knee_anlge        9\n",
       "left_ankle_angle_1      9\n",
       "left_ankle_angle_2      9\n",
       "right_ankle_angle_1     9\n",
       "right_ankle_angle_2     9\n",
       "hip_x_diff              9\n",
       "hip_y_diff              9\n",
       "hip_depth_diff          9\n",
       "knee_x_diff             9\n",
       "knee_y_diff             9\n",
       "knee_depth_diff         9\n",
       "ankle_x_diff            9\n",
       "ankle_y_diff            9\n",
       "ankle_depth_diff        9\n",
       "heel_x_diff             9\n",
       "heel_y_diff             9\n",
       "heel_depth_diff         9\n",
       "footindex_x_diff        9\n",
       "footindex_y_diff        9\n",
       "footindex_depth_diff    9\n",
       "hip_length              9\n",
       "knee_length             9\n",
       "ankle_length            9\n",
       "heel_length             9\n",
       "footindex_length        9\n",
       "class                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135601, 28)\n",
      "(135601,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, :-1]\n",
    "Y = dataset.iloc[:, 28]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "0    39096\n",
      "1    10189\n",
      "2    10251\n",
      "3    13863\n",
      "4    10418\n",
      "5    11996\n",
      "6    39788\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.groupby(Y).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize는 Batch Normalization 으로 진행해본다.\n",
    "#scaler = MinMaxScaler(feature_range=(0,1))\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108480, 28) (27121, 28) (108480, 7) (27121, 7)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class를 위에서 one-hot encoding함.\n",
    "#y_train = pd.get_dummies(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.values\n",
    "#y_train = y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성 및 학습\n",
    "\n",
    "-- 현재 baseline_model 을 사용한 estimator2 가 accuracy :0.9203569189926625, roc : 0.9941785312029153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Dense, Activation\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickletools import optimize\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    # input_dim 개수는 features 개수, 근데 unit의 수를 feature 개수라 한 자료도 있음. -> 아직 잘 모르겠음\n",
    "    model.add(Dense(50, input_dim = 28))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax')) # Softmax for multi-class classification\n",
    "    \n",
    "    # Compile model here\n",
    "    sgd = optimizers.SGD(lr=0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(model= baseline_model, epochs = 100, batch_size = 10, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4756c5950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4756c5950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc477d1ad08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc477d1ad08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "history = estimator.fit(X_train, y_train, validation_split = 0.3, epochs = 100, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8987869178865087\n"
     ]
    }
   ],
   "source": [
    "results = estimator.score(X_test, y_test)\n",
    "print('Test accuracy: ', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model2():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    # input_dim 개수는 features 개수, 근데 unit의 수를 feature 개수라 한 자료도 있음. -> 아직 잘 모르겠음\n",
    "    model.add(Dense(50, input_dim = 28))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax')) # Softmax for multi-class classification\n",
    "    \n",
    "    # Compile model here\n",
    "    sgd = optimizers.SGD(lr=0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model3():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    # input_dim 개수는 features 개수, 근데 unit의 수를 feature 개수라 한 자료도 있음. -> 아직 잘 모르겠음\n",
    "    model.add(Dense(100, input_dim = 28))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax')) # Softmax for multi-class classification\n",
    "    \n",
    "    # Compile model here\n",
    "    sgd = optimizers.SGD(lr=0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model4():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    # input_dim 개수는 features 개수, 근데 unit의 수를 feature 개수라 한 자료도 있음. -> 아직 잘 모르겠음\n",
    "    model.add(Dense(100, input_dim = 28))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax')) # Softmax for multi-class classification\n",
    "    \n",
    "    # Compile model here\n",
    "    sgd = optimizers.SGD(lr=0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator2 = KerasClassifier(model= baseline_model, epochs = 150, batch_size = 10, verbose = 0)\n",
    "estimator3 = KerasClassifier(model= baseline_model2, epochs = 100, batch_size = 10, verbose = 0)\n",
    "estimator4 = KerasClassifier(model= baseline_model2, epochs = 150, batch_size = 10, verbose = 0)\n",
    "estimator5 = KerasClassifier(model= baseline_model3, epochs = 150, batch_size = 10, verbose = 0)\n",
    "estimator5 = KerasClassifier(model= baseline_model4, epochs = 150, batch_size = 10, verbose = 0)\n",
    "#Multilabel and multi-output classification is not supported.\n",
    "#ensemble_clf = VotingClassifier(estimators = [('model1', estimator), ('model2', estimator2),('model3', estimator3),('model4', estimator4),('model5', estimator5)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a2785b70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a2785b70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy estimator2:  0.8987869178865087\n"
     ]
    }
   ],
   "source": [
    "estimator2.fit(X_train, y_train)\n",
    "results2 = estimator.score(X_test, y_test)\n",
    "print('Test accuracy estimator2: ', results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc478368400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc478368400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Test accuracy estimator4:  0.9203569189926625\n"
     ]
    }
   ],
   "source": [
    "results2 = estimator2.score(X_test, y_test)\n",
    "print('Test accuracy estimator2: ', results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a27852f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a27852f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Test accuracy estimator3:  0.8987869178865087\n"
     ]
    }
   ],
   "source": [
    "estimator3.fit(X_train, y_train)\n",
    "results3 = estimator.score(X_test, y_test)\n",
    "print('Test accuracy estimator3: ', results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4687aa6a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4687aa6a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Test accuracy estimator3:  0.864533018694001\n"
     ]
    }
   ],
   "source": [
    "results3 = estimator3.score(X_test, y_test)\n",
    "print('Test accuracy estimator3: ', results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc466981840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc466981840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy estimator4:  0.8987869178865087\n"
     ]
    }
   ],
   "source": [
    "estimator4.fit(X_train, y_train)\n",
    "results4 = estimator.score(X_test, y_test)\n",
    "print('Test accuracy estimator4: ', results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc48505b950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc48505b950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Test accuracy estimator4:  0.8802035323181299\n"
     ]
    }
   ],
   "source": [
    "results4 = estimator4.score(X_test, y_test)\n",
    "print('Test accuracy estimator4: ', results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4680656a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4680656a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy estimator5:  0.8987869178865087\n"
     ]
    }
   ],
   "source": [
    "estimator5.fit(X_train, y_train)\n",
    "results5 = estimator.score(X_test, y_test)\n",
    "print('Test accuracy estimator5: ', results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy estimator4:  0.8910069687695882\n"
     ]
    }
   ],
   "source": [
    "results5 = estimator5.score(X_test, y_test)\n",
    "print('Test accuracy estimator4: ', results5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'loss': [1.4249285459518433,\n",
       "              1.2386306524276733,\n",
       "              1.1776974201202393,\n",
       "              1.13893461227417,\n",
       "              1.1071150302886963,\n",
       "              1.0801610946655273,\n",
       "              1.0530831813812256,\n",
       "              1.0352083444595337,\n",
       "              1.0163005590438843,\n",
       "              1.001890778541565,\n",
       "              0.9855893850326538,\n",
       "              0.9714383482933044,\n",
       "              0.9579511284828186,\n",
       "              0.9466728568077087,\n",
       "              0.9342707991600037,\n",
       "              0.9199480414390564,\n",
       "              0.9085633754730225,\n",
       "              0.9004871845245361,\n",
       "              0.8901311755180359,\n",
       "              0.8822671175003052,\n",
       "              0.8746345043182373,\n",
       "              0.8645093441009521,\n",
       "              0.8542525768280029,\n",
       "              0.8492755889892578,\n",
       "              0.8403607606887817,\n",
       "              0.8346517086029053,\n",
       "              0.8236793279647827,\n",
       "              0.8221891522407532,\n",
       "              0.8140502572059631,\n",
       "              0.8064175844192505,\n",
       "              0.8026924729347229,\n",
       "              0.79689621925354,\n",
       "              0.7900487184524536,\n",
       "              0.7816031575202942,\n",
       "              0.777977705001831,\n",
       "              0.7719866037368774,\n",
       "              0.7707700729370117,\n",
       "              0.7623454332351685,\n",
       "              0.760521650314331,\n",
       "              0.7549532651901245,\n",
       "              0.7496665120124817,\n",
       "              0.7486667037010193,\n",
       "              0.7426838278770447,\n",
       "              0.7413074374198914,\n",
       "              0.7338635325431824,\n",
       "              0.7329985499382019,\n",
       "              0.7238205671310425,\n",
       "              0.7264893054962158,\n",
       "              0.7210463881492615,\n",
       "              0.7187229990959167,\n",
       "              0.7162080407142639,\n",
       "              0.7128604054450989,\n",
       "              0.7076385617256165,\n",
       "              0.705988347530365,\n",
       "              0.7009236216545105,\n",
       "              0.7016271948814392,\n",
       "              0.6964995861053467,\n",
       "              0.6978549957275391,\n",
       "              0.691379964351654,\n",
       "              0.6896548271179199,\n",
       "              0.6843323111534119,\n",
       "              0.6849166750907898,\n",
       "              0.680268406867981,\n",
       "              0.6802183985710144,\n",
       "              0.676033079624176,\n",
       "              0.676949143409729,\n",
       "              0.6760472655296326,\n",
       "              0.6668924689292908,\n",
       "              0.6681554317474365,\n",
       "              0.6611306667327881,\n",
       "              0.6647251844406128,\n",
       "              0.6596652269363403,\n",
       "              0.6576464176177979,\n",
       "              0.6574517488479614,\n",
       "              0.6569435596466064,\n",
       "              0.6548054814338684,\n",
       "              0.6486619114875793,\n",
       "              0.6461087465286255,\n",
       "              0.6455147862434387,\n",
       "              0.641153872013092,\n",
       "              0.6446470022201538,\n",
       "              0.6448131799697876,\n",
       "              0.636837363243103,\n",
       "              0.6362937688827515,\n",
       "              0.6354923844337463,\n",
       "              0.6320562362670898,\n",
       "              0.6316774487495422,\n",
       "              0.6276159882545471,\n",
       "              0.6289279460906982,\n",
       "              0.6244016289710999,\n",
       "              0.6240078806877136,\n",
       "              0.6235448718070984,\n",
       "              0.6222201585769653,\n",
       "              0.6207302808761597,\n",
       "              0.6221162676811218,\n",
       "              0.6148902773857117,\n",
       "              0.6164592504501343,\n",
       "              0.6177375912666321,\n",
       "              0.6109706163406372,\n",
       "              0.6098126769065857,\n",
       "              0.6096537709236145,\n",
       "              0.6081486940383911,\n",
       "              0.6074854731559753,\n",
       "              0.6079078316688538,\n",
       "              0.6049860715866089,\n",
       "              0.6026825904846191,\n",
       "              0.6010856628417969,\n",
       "              0.5976681709289551,\n",
       "              0.6007135510444641,\n",
       "              0.594879686832428,\n",
       "              0.5917588472366333,\n",
       "              0.5936931371688843,\n",
       "              0.5894759297370911,\n",
       "              0.5941078662872314,\n",
       "              0.5908100008964539,\n",
       "              0.5873738527297974,\n",
       "              0.5884255170822144,\n",
       "              0.5850457549095154,\n",
       "              0.5869042873382568,\n",
       "              0.5829567909240723,\n",
       "              0.5842100977897644,\n",
       "              0.5811634063720703,\n",
       "              0.5770279765129089,\n",
       "              0.577512264251709,\n",
       "              0.580957293510437,\n",
       "              0.5785635113716125,\n",
       "              0.5741205811500549,\n",
       "              0.57740318775177,\n",
       "              0.5763145685195923,\n",
       "              0.5752663016319275,\n",
       "              0.573144257068634,\n",
       "              0.5709327459335327,\n",
       "              0.5731759667396545,\n",
       "              0.5722254514694214,\n",
       "              0.5682908892631531,\n",
       "              0.5656887292861938,\n",
       "              0.5650980472564697,\n",
       "              0.5676566362380981,\n",
       "              0.5671460032463074,\n",
       "              0.5696825981140137,\n",
       "              0.5624909996986389,\n",
       "              0.5616939067840576,\n",
       "              0.5664293169975281,\n",
       "              0.558246910572052,\n",
       "              0.5568925142288208,\n",
       "              0.5606205463409424,\n",
       "              0.5603228211402893,\n",
       "              0.5594567656517029,\n",
       "              0.5583821535110474,\n",
       "              0.5579777956008911],\n",
       "             'accuracy': [0.5105733871459961,\n",
       "              0.5747418999671936,\n",
       "              0.5960361361503601,\n",
       "              0.6110342741012573,\n",
       "              0.6208609938621521,\n",
       "              0.6295169591903687,\n",
       "              0.6400166153907776,\n",
       "              0.6450129151344299,\n",
       "              0.6522584557533264,\n",
       "              0.656213104724884,\n",
       "              0.6619745492935181,\n",
       "              0.6668602228164673,\n",
       "              0.6696810722351074,\n",
       "              0.6736725568771362,\n",
       "              0.6788163781166077,\n",
       "              0.6816555857658386,\n",
       "              0.6872326731681824,\n",
       "              0.6891961693763733,\n",
       "              0.6938790678977966,\n",
       "              0.6952894330024719,\n",
       "              0.6968749761581421,\n",
       "              0.7008112072944641,\n",
       "              0.7053097486495972,\n",
       "              0.706849217414856,\n",
       "              0.7094855904579163,\n",
       "              0.7102968096733093,\n",
       "              0.7152101993560791,\n",
       "              0.7153023481369019,\n",
       "              0.7191187143325806,\n",
       "              0.7226585745811462,\n",
       "              0.7224280834197998,\n",
       "              0.7236080169677734,\n",
       "              0.7286596894264221,\n",
       "              0.7305678725242615,\n",
       "              0.7308443784713745,\n",
       "              0.7329738140106201,\n",
       "              0.7338219285011292,\n",
       "              0.7356471419334412,\n",
       "              0.736900806427002,\n",
       "              0.7383480668067932,\n",
       "              0.7410398125648499,\n",
       "              0.7408462166786194,\n",
       "              0.7426714897155762,\n",
       "              0.7448469996452332,\n",
       "              0.7458056807518005,\n",
       "              0.745750367641449,\n",
       "              0.7492809891700745,\n",
       "              0.7493916153907776,\n",
       "              0.7502949833869934,\n",
       "              0.751926600933075,\n",
       "              0.752673327922821,\n",
       "              0.7535951137542725,\n",
       "              0.7555032968521118,\n",
       "              0.7563698291778564,\n",
       "              0.7577617764472961,\n",
       "              0.757586658000946,\n",
       "              0.7584531903266907,\n",
       "              0.7578908801078796,\n",
       "              0.7599741816520691,\n",
       "              0.7616150379180908,\n",
       "              0.7633019685745239,\n",
       "              0.7626290321350098,\n",
       "              0.7645741105079651,\n",
       "              0.7640855312347412,\n",
       "              0.7652839422225952,\n",
       "              0.7663901448249817,\n",
       "              0.7667680382728577,\n",
       "              0.769976019859314,\n",
       "              0.7689067125320435,\n",
       "              0.7710822224617004,\n",
       "              0.7685748338699341,\n",
       "              0.7725387215614319,\n",
       "              0.7725571393966675,\n",
       "              0.7734513282775879,\n",
       "              0.7731286883354187,\n",
       "              0.7741795778274536,\n",
       "              0.7757558822631836,\n",
       "              0.7782171964645386,\n",
       "              0.7768252491950989,\n",
       "              0.7784937024116516,\n",
       "              0.7767791152000427,\n",
       "              0.7766684889793396,\n",
       "              0.7798027396202087,\n",
       "              0.7805217504501343,\n",
       "              0.7807983160018921,\n",
       "              0.7819413542747498,\n",
       "              0.7820519804954529,\n",
       "              0.7836006879806519,\n",
       "              0.7836098670959473,\n",
       "              0.7843841910362244,\n",
       "              0.7845317125320435,\n",
       "              0.7851677536964417,\n",
       "              0.786762535572052,\n",
       "              0.7860435247421265,\n",
       "              0.7847068309783936,\n",
       "              0.7876935601234436,\n",
       "              0.7874631285667419,\n",
       "              0.7867901921272278,\n",
       "              0.7899796962738037,\n",
       "              0.7909845113754272,\n",
       "              0.7911504507064819,\n",
       "              0.7899981737136841,\n",
       "              0.7910858988761902,\n",
       "              0.7921921014785767,\n",
       "              0.7920814752578735,\n",
       "              0.7924410104751587,\n",
       "              0.7938975095748901,\n",
       "              0.7945612072944641,\n",
       "              0.7937960624694824,\n",
       "              0.7954830527305603,\n",
       "              0.7970409393310547,\n",
       "              0.7968289256095886,\n",
       "              0.7979535460472107,\n",
       "              0.7967920303344727,\n",
       "              0.7970501184463501,\n",
       "              0.7999078035354614,\n",
       "              0.7976216673851013,\n",
       "              0.7998156547546387,\n",
       "              0.799050509929657,\n",
       "              0.7996036410331726,\n",
       "              0.797824501991272,\n",
       "              0.8007927536964417,\n",
       "              0.8014103770256042,\n",
       "              0.8018621206283569,\n",
       "              0.8008573055267334,\n",
       "              0.8010047674179077,\n",
       "              0.8029775023460388,\n",
       "              0.8023045659065247,\n",
       "              0.8023691177368164,\n",
       "              0.8026548624038696,\n",
       "              0.8035306334495544,\n",
       "              0.8059089183807373,\n",
       "              0.8024705052375793,\n",
       "              0.8037794828414917,\n",
       "              0.8058996796607971,\n",
       "              0.8061485886573792,\n",
       "              0.8060932755470276,\n",
       "              0.8062684535980225,\n",
       "              0.8052083253860474,\n",
       "              0.8054664731025696,\n",
       "              0.807337760925293,\n",
       "              0.8079830408096313,\n",
       "              0.8075590133666992,\n",
       "              0.8093012571334839,\n",
       "              0.8084439635276794,\n",
       "              0.8080936670303345,\n",
       "              0.8078078627586365,\n",
       "              0.8087020516395569,\n",
       "              0.809162974357605,\n",
       "              0.8078171014785767]})"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results5_history = estimator5.history_\n",
    "results5_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc484f23158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc484f23158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.2222341e-03, 7.3583210e-01, 7.6279277e-04, ..., 4.4046948e-03,\n",
       "        4.6327603e-03, 1.0258709e-01],\n",
       "       [9.9458271e-01, 1.0999545e-03, 4.1416328e-04, ..., 7.1378198e-04,\n",
       "        2.4794736e-03, 5.6722300e-04],\n",
       "       [1.5377022e-03, 2.1815246e-03, 9.4936144e-01, ..., 3.0934433e-02,\n",
       "        3.3191394e-04, 1.7160517e-03],\n",
       "       ...,\n",
       "       [9.8921573e-01, 2.8655832e-04, 5.7333719e-04, ..., 2.0053848e-03,\n",
       "        7.2435951e-03, 1.5405694e-04],\n",
       "       [3.2958006e-03, 1.2157457e-03, 8.7075597e-01, ..., 1.0931589e-01,\n",
       "        1.9772314e-04, 8.3567929e-03],\n",
       "       [1.5004690e-02, 1.8944022e-03, 5.8597121e-02, ..., 1.4192044e-02,\n",
       "        1.7729906e-03, 1.5023066e-01]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results5_ = estimator5.predict_proba(X_test)\n",
    "results5_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27121, 7)\n",
      "(27121, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(results5_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = estimator2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941785312029153"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC-ROC score\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "score2_auc= roc_auc_score(y_test, y_pred )\n",
    "score2_auc #0.9941785312029153\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989658834746484"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC-ROC score\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "score5_auc= roc_auc_score(y_test, results5_ )\n",
    "score5_auc #0.989658834746484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-b4ec6ca96b57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore5_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults5_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore5_f1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f-score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "score5_f1 = f1_score(y_test, results5_, average='samples')\n",
    "score5_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ensemble_clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = []\n",
    "y_pred = ensemble_clf.predict(X_test)\n",
    "print('Acc: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d29d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d29d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc486071ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc486071ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc487e13e18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc487e13e18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc48a43e9d8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc48a43e9d8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc48a178ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc48a178ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4860aa950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4860aa950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4783c2bf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4783c2bf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4783e2158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4783e2158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc48a43e488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc48a43e488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc484d257b8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc484d257b8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X_train, y_train, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d25c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d25c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a3dd6840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a3dd6840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4850d10d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4850d10d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d0cae8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d0cae8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a3dd6840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a3dd6840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 1494, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 767, in fit\n",
      "    **kwargs,\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "    **kwargs,\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n",
      "    target.shape.assert_is_compatible_with(output.shape)\n",
      "ValueError: Shapes (10, 1) and (10, 7) are incompatible\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 1494, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 767, in fit\n",
      "    **kwargs,\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "    **kwargs,\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n",
      "    target.shape.assert_is_compatible_with(output.shape)\n",
      "ValueError: Shapes (None, 1) and (None, 7) are incompatible\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X, Y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 77.00% (1.30%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Result: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484f02730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484f02730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=<function baseline_model at 0x7fc484a84378>\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=10\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-2cd4185e6ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#모델 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "#모델 저장\n",
    "estimator.save(\"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 불러오기\n",
    "import keras\n",
    "reconstructed_model = keras.models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import module.feature_extract as feature\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done [demo/demo.mp4] \n"
     ]
    }
   ],
   "source": [
    "dataframe = feature.extract_keypoint(path = \"demo/demo.mp4\", \n",
    "                                    save_path = \"demo/\",\n",
    "                                    show_video = False, save_file_name = \"normalize_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>nose_z</th>\n",
       "      <th>left_eye_inner_x</th>\n",
       "      <th>left_eye_inner_y</th>\n",
       "      <th>left_eye_inner_z</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>left_eye_z</th>\n",
       "      <th>left_eye_outer_x</th>\n",
       "      <th>...</th>\n",
       "      <th>left_heel_z</th>\n",
       "      <th>right_heel_x</th>\n",
       "      <th>right_heel_y</th>\n",
       "      <th>right_heel_z</th>\n",
       "      <th>left_foot_index_x</th>\n",
       "      <th>left_foot_index_y</th>\n",
       "      <th>left_foot_index_z</th>\n",
       "      <th>right_foot_index_x</th>\n",
       "      <th>right_foot_index_y</th>\n",
       "      <th>right_foot_index_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189573</td>\n",
       "      <td>-0.597068</td>\n",
       "      <td>-0.163225</td>\n",
       "      <td>0.164992</td>\n",
       "      <td>-0.641987</td>\n",
       "      <td>-0.153325</td>\n",
       "      <td>0.165396</td>\n",
       "      <td>-0.642102</td>\n",
       "      <td>-0.152595</td>\n",
       "      <td>0.165288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>-0.074937</td>\n",
       "      <td>0.806014</td>\n",
       "      <td>0.040866</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>0.828724</td>\n",
       "      <td>0.167491</td>\n",
       "      <td>0.042717</td>\n",
       "      <td>0.835529</td>\n",
       "      <td>-0.055435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.193588</td>\n",
       "      <td>-0.603334</td>\n",
       "      <td>-0.149474</td>\n",
       "      <td>0.167534</td>\n",
       "      <td>-0.646749</td>\n",
       "      <td>-0.137942</td>\n",
       "      <td>0.167917</td>\n",
       "      <td>-0.646882</td>\n",
       "      <td>-0.137253</td>\n",
       "      <td>0.167712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205442</td>\n",
       "      <td>-0.085021</td>\n",
       "      <td>0.802507</td>\n",
       "      <td>0.035435</td>\n",
       "      <td>0.042096</td>\n",
       "      <td>0.823012</td>\n",
       "      <td>0.151791</td>\n",
       "      <td>0.023676</td>\n",
       "      <td>0.831995</td>\n",
       "      <td>-0.059656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.211302</td>\n",
       "      <td>-0.615537</td>\n",
       "      <td>-0.139884</td>\n",
       "      <td>0.186049</td>\n",
       "      <td>-0.658645</td>\n",
       "      <td>-0.128379</td>\n",
       "      <td>0.186389</td>\n",
       "      <td>-0.658804</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>0.186094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213280</td>\n",
       "      <td>-0.098092</td>\n",
       "      <td>0.792451</td>\n",
       "      <td>0.047457</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>0.805992</td>\n",
       "      <td>0.166923</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.824457</td>\n",
       "      <td>-0.049063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.217025</td>\n",
       "      <td>-0.623345</td>\n",
       "      <td>-0.139500</td>\n",
       "      <td>0.192396</td>\n",
       "      <td>-0.666512</td>\n",
       "      <td>-0.128613</td>\n",
       "      <td>0.192676</td>\n",
       "      <td>-0.666626</td>\n",
       "      <td>-0.127903</td>\n",
       "      <td>0.192430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213796</td>\n",
       "      <td>-0.129218</td>\n",
       "      <td>0.782278</td>\n",
       "      <td>0.070536</td>\n",
       "      <td>0.084782</td>\n",
       "      <td>0.796275</td>\n",
       "      <td>0.167291</td>\n",
       "      <td>-0.022285</td>\n",
       "      <td>0.816900</td>\n",
       "      <td>-0.034294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.217587</td>\n",
       "      <td>-0.621558</td>\n",
       "      <td>-0.133263</td>\n",
       "      <td>0.193579</td>\n",
       "      <td>-0.664917</td>\n",
       "      <td>-0.123402</td>\n",
       "      <td>0.193843</td>\n",
       "      <td>-0.665022</td>\n",
       "      <td>-0.122657</td>\n",
       "      <td>0.193650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213007</td>\n",
       "      <td>-0.149983</td>\n",
       "      <td>0.771653</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>0.119917</td>\n",
       "      <td>0.781949</td>\n",
       "      <td>0.166544</td>\n",
       "      <td>-0.048812</td>\n",
       "      <td>0.805134</td>\n",
       "      <td>0.001875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.172675</td>\n",
       "      <td>-0.603860</td>\n",
       "      <td>-0.098230</td>\n",
       "      <td>0.157629</td>\n",
       "      <td>-0.645690</td>\n",
       "      <td>-0.085949</td>\n",
       "      <td>0.157888</td>\n",
       "      <td>-0.645668</td>\n",
       "      <td>-0.085247</td>\n",
       "      <td>0.157707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252255</td>\n",
       "      <td>-0.020252</td>\n",
       "      <td>0.797077</td>\n",
       "      <td>0.084293</td>\n",
       "      <td>0.047086</td>\n",
       "      <td>0.842310</td>\n",
       "      <td>0.200128</td>\n",
       "      <td>0.080760</td>\n",
       "      <td>0.829856</td>\n",
       "      <td>0.010952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.172800</td>\n",
       "      <td>-0.604111</td>\n",
       "      <td>-0.100596</td>\n",
       "      <td>0.157548</td>\n",
       "      <td>-0.645890</td>\n",
       "      <td>-0.088546</td>\n",
       "      <td>0.157805</td>\n",
       "      <td>-0.645877</td>\n",
       "      <td>-0.087849</td>\n",
       "      <td>0.157620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253856</td>\n",
       "      <td>-0.019843</td>\n",
       "      <td>0.797681</td>\n",
       "      <td>0.083454</td>\n",
       "      <td>0.046662</td>\n",
       "      <td>0.837415</td>\n",
       "      <td>0.203124</td>\n",
       "      <td>0.081989</td>\n",
       "      <td>0.829422</td>\n",
       "      <td>0.009869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.172851</td>\n",
       "      <td>-0.603654</td>\n",
       "      <td>-0.103807</td>\n",
       "      <td>0.157453</td>\n",
       "      <td>-0.645369</td>\n",
       "      <td>-0.092017</td>\n",
       "      <td>0.157710</td>\n",
       "      <td>-0.645374</td>\n",
       "      <td>-0.091318</td>\n",
       "      <td>0.157522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252636</td>\n",
       "      <td>-0.020226</td>\n",
       "      <td>0.800890</td>\n",
       "      <td>0.083016</td>\n",
       "      <td>0.044516</td>\n",
       "      <td>0.837369</td>\n",
       "      <td>0.202032</td>\n",
       "      <td>0.082571</td>\n",
       "      <td>0.832004</td>\n",
       "      <td>0.007272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.172274</td>\n",
       "      <td>-0.601551</td>\n",
       "      <td>-0.108398</td>\n",
       "      <td>0.156698</td>\n",
       "      <td>-0.643332</td>\n",
       "      <td>-0.096937</td>\n",
       "      <td>0.156964</td>\n",
       "      <td>-0.643359</td>\n",
       "      <td>-0.096241</td>\n",
       "      <td>0.156786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249989</td>\n",
       "      <td>-0.020457</td>\n",
       "      <td>0.802043</td>\n",
       "      <td>0.076922</td>\n",
       "      <td>0.044526</td>\n",
       "      <td>0.836991</td>\n",
       "      <td>0.199022</td>\n",
       "      <td>0.083109</td>\n",
       "      <td>0.832080</td>\n",
       "      <td>-0.003527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.172375</td>\n",
       "      <td>-0.599843</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>0.156682</td>\n",
       "      <td>-0.641646</td>\n",
       "      <td>-0.099078</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>-0.641688</td>\n",
       "      <td>-0.098388</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245136</td>\n",
       "      <td>-0.020192</td>\n",
       "      <td>0.805493</td>\n",
       "      <td>0.065324</td>\n",
       "      <td>0.044384</td>\n",
       "      <td>0.837431</td>\n",
       "      <td>0.193021</td>\n",
       "      <td>0.082975</td>\n",
       "      <td>0.833669</td>\n",
       "      <td>-0.017390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nose_x    nose_y    nose_z  left_eye_inner_x  left_eye_inner_y  \\\n",
       "0    0.189573 -0.597068 -0.163225          0.164992         -0.641987   \n",
       "1    0.193588 -0.603334 -0.149474          0.167534         -0.646749   \n",
       "2    0.211302 -0.615537 -0.139884          0.186049         -0.658645   \n",
       "3    0.217025 -0.623345 -0.139500          0.192396         -0.666512   \n",
       "4    0.217587 -0.621558 -0.133263          0.193579         -0.664917   \n",
       "..        ...       ...       ...               ...               ...   \n",
       "134  0.172675 -0.603860 -0.098230          0.157629         -0.645690   \n",
       "135  0.172800 -0.604111 -0.100596          0.157548         -0.645890   \n",
       "136  0.172851 -0.603654 -0.103807          0.157453         -0.645369   \n",
       "137  0.172274 -0.601551 -0.108398          0.156698         -0.643332   \n",
       "138  0.172375 -0.599843 -0.110666          0.156682         -0.641646   \n",
       "\n",
       "     left_eye_inner_z  left_eye_x  left_eye_y  left_eye_z  left_eye_outer_x  \\\n",
       "0           -0.153325    0.165396   -0.642102   -0.152595          0.165288   \n",
       "1           -0.137942    0.167917   -0.646882   -0.137253          0.167712   \n",
       "2           -0.128379    0.186389   -0.658804   -0.127688          0.186094   \n",
       "3           -0.128613    0.192676   -0.666626   -0.127903          0.192430   \n",
       "4           -0.123402    0.193843   -0.665022   -0.122657          0.193650   \n",
       "..                ...         ...         ...         ...               ...   \n",
       "134         -0.085949    0.157888   -0.645668   -0.085247          0.157707   \n",
       "135         -0.088546    0.157805   -0.645877   -0.087849          0.157620   \n",
       "136         -0.092017    0.157710   -0.645374   -0.091318          0.157522   \n",
       "137         -0.096937    0.156964   -0.643359   -0.096241          0.156786   \n",
       "138         -0.099078    0.156951   -0.641688   -0.098388          0.156774   \n",
       "\n",
       "     ...  left_heel_z  right_heel_x  right_heel_y  right_heel_z  \\\n",
       "0    ...     0.219943     -0.074937      0.806014      0.040866   \n",
       "1    ...     0.205442     -0.085021      0.802507      0.035435   \n",
       "2    ...     0.213280     -0.098092      0.792451      0.047457   \n",
       "3    ...     0.213796     -0.129218      0.782278      0.070536   \n",
       "4    ...     0.213007     -0.149983      0.771653      0.102458   \n",
       "..   ...          ...           ...           ...           ...   \n",
       "134  ...     0.252255     -0.020252      0.797077      0.084293   \n",
       "135  ...     0.253856     -0.019843      0.797681      0.083454   \n",
       "136  ...     0.252636     -0.020226      0.800890      0.083016   \n",
       "137  ...     0.249989     -0.020457      0.802043      0.076922   \n",
       "138  ...     0.245136     -0.020192      0.805493      0.065324   \n",
       "\n",
       "     left_foot_index_x  left_foot_index_y  left_foot_index_z  \\\n",
       "0             0.054205           0.828724           0.167491   \n",
       "1             0.042096           0.823012           0.151791   \n",
       "2             0.034728           0.805992           0.166923   \n",
       "3             0.084782           0.796275           0.167291   \n",
       "4             0.119917           0.781949           0.166544   \n",
       "..                 ...                ...                ...   \n",
       "134           0.047086           0.842310           0.200128   \n",
       "135           0.046662           0.837415           0.203124   \n",
       "136           0.044516           0.837369           0.202032   \n",
       "137           0.044526           0.836991           0.199022   \n",
       "138           0.044384           0.837431           0.193021   \n",
       "\n",
       "     right_foot_index_x  right_foot_index_y  right_foot_index_z  \n",
       "0              0.042717            0.835529           -0.055435  \n",
       "1              0.023676            0.831995           -0.059656  \n",
       "2              0.011385            0.824457           -0.049063  \n",
       "3             -0.022285            0.816900           -0.034294  \n",
       "4             -0.048812            0.805134            0.001875  \n",
       "..                  ...                 ...                 ...  \n",
       "134            0.080760            0.829856            0.010952  \n",
       "135            0.081989            0.829422            0.009869  \n",
       "136            0.082571            0.832004            0.007272  \n",
       "137            0.083109            0.832080           -0.003527  \n",
       "138            0.082975            0.833669           -0.017390  \n",
       "\n",
       "[139 rows x 99 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = feature.cut_dataframe(dataframe, drop = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_angle = feature.compute_angle_feature(path = \"demo/normalize_demo_noramlize.csv\", save_path = \"demo/feature/\", save_file_name = \"demo\")\n",
    "feature_len = feature.compute_len_feature(path = \"demo/normalize_demo_noramlize.csv\", save_path = \"demo/feature/\", save_file_name = \"demo\")\n",
    "feature_diff = feature.compute_diff_feature(path = \"demo/normalize_demo_noramlize.csv\", save_path = \"demo/feature/\", save_file_name = \"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_hip_anlge</th>\n",
       "      <th>right_hip_anlge</th>\n",
       "      <th>left_knee_anlge</th>\n",
       "      <th>right_knee_anlge</th>\n",
       "      <th>left_ankle_angle_1</th>\n",
       "      <th>left_ankle_angle_2</th>\n",
       "      <th>right_ankle_angle_1</th>\n",
       "      <th>right_ankle_angle_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-173.305857</td>\n",
       "      <td>179.302493</td>\n",
       "      <td>178.150294</td>\n",
       "      <td>-168.207583</td>\n",
       "      <td>112.743856</td>\n",
       "      <td>112.743856</td>\n",
       "      <td>114.800891</td>\n",
       "      <td>175.388485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-175.605953</td>\n",
       "      <td>177.474837</td>\n",
       "      <td>-177.506504</td>\n",
       "      <td>-165.282441</td>\n",
       "      <td>112.814767</td>\n",
       "      <td>112.814767</td>\n",
       "      <td>115.682671</td>\n",
       "      <td>177.810875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176.198079</td>\n",
       "      <td>175.064436</td>\n",
       "      <td>-160.725922</td>\n",
       "      <td>-163.164257</td>\n",
       "      <td>107.662852</td>\n",
       "      <td>107.662852</td>\n",
       "      <td>113.843099</td>\n",
       "      <td>175.381836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170.708384</td>\n",
       "      <td>176.236211</td>\n",
       "      <td>-157.330324</td>\n",
       "      <td>-164.804320</td>\n",
       "      <td>109.957725</td>\n",
       "      <td>109.957725</td>\n",
       "      <td>113.616298</td>\n",
       "      <td>172.808559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169.468475</td>\n",
       "      <td>177.543450</td>\n",
       "      <td>-158.866434</td>\n",
       "      <td>-168.059219</td>\n",
       "      <td>114.007854</td>\n",
       "      <td>114.007854</td>\n",
       "      <td>114.947764</td>\n",
       "      <td>172.859417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-168.449193</td>\n",
       "      <td>-177.994759</td>\n",
       "      <td>172.645924</td>\n",
       "      <td>177.094187</td>\n",
       "      <td>125.679987</td>\n",
       "      <td>125.679987</td>\n",
       "      <td>128.546879</td>\n",
       "      <td>-177.803049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>-168.380617</td>\n",
       "      <td>-178.066367</td>\n",
       "      <td>172.627278</td>\n",
       "      <td>177.475257</td>\n",
       "      <td>124.847999</td>\n",
       "      <td>124.847999</td>\n",
       "      <td>127.800972</td>\n",
       "      <td>-178.089726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-168.407274</td>\n",
       "      <td>-178.276855</td>\n",
       "      <td>173.198243</td>\n",
       "      <td>178.129159</td>\n",
       "      <td>123.899273</td>\n",
       "      <td>123.899273</td>\n",
       "      <td>127.159249</td>\n",
       "      <td>-178.351186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>-168.363199</td>\n",
       "      <td>-178.171733</td>\n",
       "      <td>173.174118</td>\n",
       "      <td>178.333990</td>\n",
       "      <td>123.839059</td>\n",
       "      <td>123.839059</td>\n",
       "      <td>126.512506</td>\n",
       "      <td>-178.626175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-168.641025</td>\n",
       "      <td>-178.261178</td>\n",
       "      <td>173.179773</td>\n",
       "      <td>178.556083</td>\n",
       "      <td>123.954840</td>\n",
       "      <td>123.954840</td>\n",
       "      <td>126.012035</td>\n",
       "      <td>-178.604777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     left_hip_anlge  right_hip_anlge  left_knee_anlge  right_knee_anlge  \\\n",
       "0       -173.305857       179.302493       178.150294       -168.207583   \n",
       "1       -175.605953       177.474837      -177.506504       -165.282441   \n",
       "2        176.198079       175.064436      -160.725922       -163.164257   \n",
       "3        170.708384       176.236211      -157.330324       -164.804320   \n",
       "4        169.468475       177.543450      -158.866434       -168.059219   \n",
       "..              ...              ...              ...               ...   \n",
       "134     -168.449193      -177.994759       172.645924        177.094187   \n",
       "135     -168.380617      -178.066367       172.627278        177.475257   \n",
       "136     -168.407274      -178.276855       173.198243        178.129159   \n",
       "137     -168.363199      -178.171733       173.174118        178.333990   \n",
       "138     -168.641025      -178.261178       173.179773        178.556083   \n",
       "\n",
       "     left_ankle_angle_1  left_ankle_angle_2  right_ankle_angle_1  \\\n",
       "0            112.743856          112.743856           114.800891   \n",
       "1            112.814767          112.814767           115.682671   \n",
       "2            107.662852          107.662852           113.843099   \n",
       "3            109.957725          109.957725           113.616298   \n",
       "4            114.007854          114.007854           114.947764   \n",
       "..                  ...                 ...                  ...   \n",
       "134          125.679987          125.679987           128.546879   \n",
       "135          124.847999          124.847999           127.800972   \n",
       "136          123.899273          123.899273           127.159249   \n",
       "137          123.839059          123.839059           126.512506   \n",
       "138          123.954840          123.954840           126.012035   \n",
       "\n",
       "     right_ankle_angle_2  \n",
       "0             175.388485  \n",
       "1             177.810875  \n",
       "2             175.381836  \n",
       "3             172.808559  \n",
       "4             172.859417  \n",
       "..                   ...  \n",
       "134          -177.803049  \n",
       "135          -178.089726  \n",
       "136          -178.351186  \n",
       "137          -178.626175  \n",
       "138          -178.604777  \n",
       "\n",
       "[139 rows x 8 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = pd.concat([feature_angle, feature_diff, feature_len], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139 entries, 0 to 138\n",
      "Data columns (total 28 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   left_hip_anlge        139 non-null    float64\n",
      " 1   right_hip_anlge       139 non-null    float64\n",
      " 2   left_knee_anlge       139 non-null    float64\n",
      " 3   right_knee_anlge      139 non-null    float64\n",
      " 4   left_ankle_angle_1    139 non-null    float64\n",
      " 5   left_ankle_angle_2    139 non-null    float64\n",
      " 6   right_ankle_angle_1   139 non-null    float64\n",
      " 7   right_ankle_angle_2   139 non-null    float64\n",
      " 8   hip_x_diff            139 non-null    float64\n",
      " 9   hip_y_diff            139 non-null    float64\n",
      " 10  hip_depth_diff        139 non-null    float64\n",
      " 11  knee_x_diff           139 non-null    float64\n",
      " 12  knee_y_diff           139 non-null    float64\n",
      " 13  knee_depth_diff       139 non-null    float64\n",
      " 14  ankle_x_diff          139 non-null    float64\n",
      " 15  ankle_y_diff          139 non-null    float64\n",
      " 16  ankle_depth_diff      139 non-null    float64\n",
      " 17  heel_x_diff           139 non-null    float64\n",
      " 18  heel_y_diff           139 non-null    float64\n",
      " 19  heel_depth_diff       139 non-null    float64\n",
      " 20  footindex_x_diff      139 non-null    float64\n",
      " 21  footindex_y_diff      139 non-null    float64\n",
      " 22  footindex_depth_diff  139 non-null    float64\n",
      " 23  hip_length            139 non-null    float64\n",
      " 24  knee_length           139 non-null    float64\n",
      " 25  ankle_length          139 non-null    float64\n",
      " 26  heel_length           139 non-null    float64\n",
      " 27  footindex_length      139 non-null    float64\n",
      "dtypes: float64(28)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "feature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc474dae840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc474dae840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "result =  estimator.predict(feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Got y with dtype int64, but this KerasClassifier expected uint8 and casting from int64 to uint8 is not safe!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-5adf3ad25da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \"\"\"\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# validate y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;31m# validate sample weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, y_numeric)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_dtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     raise ValueError(\n\u001b[0;32m--> 643\u001b[0;31m                         \u001b[0;34mf\"Got y with dtype {y_dtype_},\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m                         \u001b[0;34mf\" but this {self.__name__} expected {self.y_dtype_}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                         \u001b[0;34mf\" and casting from {y_dtype_} to {self.y_dtype_} is not safe!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Got y with dtype int64, but this KerasClassifier expected uint8 and casting from int64 to uint8 is not safe!"
     ]
    }
   ],
   "source": [
    "# In[44]:\n",
    "\n",
    "predictions = estimator.predict(X_test)\n",
    "print(set(predictions))\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "print ('macro f1:', f1_score(y_test, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=7)\n",
    "#y_test = tf.keras.utils.to_categorical(y_test, num_classes=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108480, 28) (108480,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'describe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-bec2ed01d95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'describe'"
     ]
    }
   ],
   "source": [
    "X_train.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=28, input_dim = X_train.shape[1], activation='relu'),\n",
    "    tf.keras.layers.Dense(units=14, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-47dfd6cafb4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07),\n\u001b[1;32m      2\u001b[0m             loss='binary_crossentropy', metrics=['accuracy'])\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2870\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2871\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m           'the model on a batch of data.')\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07),\n",
    "            loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a2c87840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a2c87840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`logits` and `labels` must have the same shape, received ((None, 7) vs (None, 1)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-18380ce07a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m   5281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5282\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5285\u001b[0m   if (not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable)) and\n",
      "\u001b[0;31mValueError\u001b[0m: `logits` and `labels` must have the same shape, received ((None, 7) vs (None, 1))."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=25, batch_size=32, validation_split=0.25, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tens')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9805838b4ba203dcba0674bac8b279717a6e59177d23b2f0adf4ed7cf39b318e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
