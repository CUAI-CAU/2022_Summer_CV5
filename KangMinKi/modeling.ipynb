{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Keras \n",
    "- using nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"result/features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_hip_anlge</th>\n",
       "      <th>right_hip_anlge</th>\n",
       "      <th>left_knee_anlge</th>\n",
       "      <th>right_knee_anlge</th>\n",
       "      <th>left_ankle_angle_1</th>\n",
       "      <th>left_ankle_angle_2</th>\n",
       "      <th>right_ankle_angle_1</th>\n",
       "      <th>right_ankle_angle_2</th>\n",
       "      <th>hip_x_diff</th>\n",
       "      <th>hip_y_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>heel_depth_diff</th>\n",
       "      <th>footindex_x_diff</th>\n",
       "      <th>footindex_y_diff</th>\n",
       "      <th>footindex_depth_diff</th>\n",
       "      <th>hip_length</th>\n",
       "      <th>knee_length</th>\n",
       "      <th>ankle_length</th>\n",
       "      <th>heel_length</th>\n",
       "      <th>footindex_length</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152.990016</td>\n",
       "      <td>143.001878</td>\n",
       "      <td>-175.706858</td>\n",
       "      <td>-167.176073</td>\n",
       "      <td>124.687808</td>\n",
       "      <td>124.687808</td>\n",
       "      <td>117.753249</td>\n",
       "      <td>178.871808</td>\n",
       "      <td>-0.022037</td>\n",
       "      <td>-0.010157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209389</td>\n",
       "      <td>-0.005688</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>-0.246590</td>\n",
       "      <td>0.024265</td>\n",
       "      <td>0.029204</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153.089893</td>\n",
       "      <td>143.214624</td>\n",
       "      <td>-176.153893</td>\n",
       "      <td>-167.000301</td>\n",
       "      <td>125.901900</td>\n",
       "      <td>125.901900</td>\n",
       "      <td>119.170554</td>\n",
       "      <td>178.859718</td>\n",
       "      <td>-0.021962</td>\n",
       "      <td>-0.010169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209575</td>\n",
       "      <td>-0.010760</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>-0.246531</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.029707</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0.029309</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153.313472</td>\n",
       "      <td>143.486636</td>\n",
       "      <td>-175.592888</td>\n",
       "      <td>-166.703123</td>\n",
       "      <td>125.525454</td>\n",
       "      <td>125.525454</td>\n",
       "      <td>120.885401</td>\n",
       "      <td>179.617597</td>\n",
       "      <td>-0.021918</td>\n",
       "      <td>-0.010162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210042</td>\n",
       "      <td>-0.014307</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>-0.247234</td>\n",
       "      <td>0.024160</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>0.031547</td>\n",
       "      <td>0.028907</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153.397308</td>\n",
       "      <td>143.567509</td>\n",
       "      <td>-175.258291</td>\n",
       "      <td>-166.461172</td>\n",
       "      <td>125.352400</td>\n",
       "      <td>125.352400</td>\n",
       "      <td>120.464476</td>\n",
       "      <td>179.698710</td>\n",
       "      <td>-0.021915</td>\n",
       "      <td>-0.010131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209887</td>\n",
       "      <td>-0.013344</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>-0.247226</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>0.030935</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153.443670</td>\n",
       "      <td>143.492207</td>\n",
       "      <td>-174.962993</td>\n",
       "      <td>-166.405916</td>\n",
       "      <td>124.336604</td>\n",
       "      <td>124.336604</td>\n",
       "      <td>119.684258</td>\n",
       "      <td>179.568240</td>\n",
       "      <td>-0.021736</td>\n",
       "      <td>-0.010054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209237</td>\n",
       "      <td>-0.011709</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>-0.247245</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>0.034196</td>\n",
       "      <td>0.030836</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135605</th>\n",
       "      <td>-172.103115</td>\n",
       "      <td>-178.989007</td>\n",
       "      <td>151.224142</td>\n",
       "      <td>164.686950</td>\n",
       "      <td>-119.294532</td>\n",
       "      <td>-119.294532</td>\n",
       "      <td>-109.548147</td>\n",
       "      <td>-169.571432</td>\n",
       "      <td>-0.091402</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241113</td>\n",
       "      <td>-0.046102</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>0.265046</td>\n",
       "      <td>0.091595</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.016802</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>0.052844</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135606</th>\n",
       "      <td>-171.450864</td>\n",
       "      <td>-178.724279</td>\n",
       "      <td>153.743514</td>\n",
       "      <td>166.360879</td>\n",
       "      <td>-116.781227</td>\n",
       "      <td>-116.781227</td>\n",
       "      <td>-111.486480</td>\n",
       "      <td>-169.417255</td>\n",
       "      <td>-0.090995</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245908</td>\n",
       "      <td>-0.024700</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.271999</td>\n",
       "      <td>0.091194</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.031789</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135607</th>\n",
       "      <td>-170.175042</td>\n",
       "      <td>-179.811477</td>\n",
       "      <td>158.854289</td>\n",
       "      <td>171.105270</td>\n",
       "      <td>-115.371234</td>\n",
       "      <td>-115.371234</td>\n",
       "      <td>-112.017345</td>\n",
       "      <td>-171.917360</td>\n",
       "      <td>-0.079152</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248112</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>0.021912</td>\n",
       "      <td>0.273472</td>\n",
       "      <td>0.079391</td>\n",
       "      <td>0.030440</td>\n",
       "      <td>0.053772</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135608</th>\n",
       "      <td>-170.287840</td>\n",
       "      <td>179.997941</td>\n",
       "      <td>158.786340</td>\n",
       "      <td>171.833840</td>\n",
       "      <td>-112.702916</td>\n",
       "      <td>-112.702916</td>\n",
       "      <td>-111.178383</td>\n",
       "      <td>-171.181592</td>\n",
       "      <td>-0.077574</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240782</td>\n",
       "      <td>0.028780</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>0.266361</td>\n",
       "      <td>0.077833</td>\n",
       "      <td>0.031844</td>\n",
       "      <td>0.049678</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>0.036268</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135609</th>\n",
       "      <td>-166.008801</td>\n",
       "      <td>-179.520176</td>\n",
       "      <td>161.389140</td>\n",
       "      <td>171.503279</td>\n",
       "      <td>-118.268117</td>\n",
       "      <td>-118.268117</td>\n",
       "      <td>-111.726932</td>\n",
       "      <td>-170.416124</td>\n",
       "      <td>-0.072327</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249770</td>\n",
       "      <td>0.109860</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.275109</td>\n",
       "      <td>0.072610</td>\n",
       "      <td>0.063430</td>\n",
       "      <td>0.127003</td>\n",
       "      <td>0.125666</td>\n",
       "      <td>0.111881</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135610 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        left_hip_anlge  right_hip_anlge  left_knee_anlge  right_knee_anlge  \\\n",
       "0           152.990016       143.001878      -175.706858       -167.176073   \n",
       "1           153.089893       143.214624      -176.153893       -167.000301   \n",
       "2           153.313472       143.486636      -175.592888       -166.703123   \n",
       "3           153.397308       143.567509      -175.258291       -166.461172   \n",
       "4           153.443670       143.492207      -174.962993       -166.405916   \n",
       "...                ...              ...              ...               ...   \n",
       "135605     -172.103115      -178.989007       151.224142        164.686950   \n",
       "135606     -171.450864      -178.724279       153.743514        166.360879   \n",
       "135607     -170.175042      -179.811477       158.854289        171.105270   \n",
       "135608     -170.287840       179.997941       158.786340        171.833840   \n",
       "135609     -166.008801      -179.520176       161.389140        171.503279   \n",
       "\n",
       "        left_ankle_angle_1  left_ankle_angle_2  right_ankle_angle_1  \\\n",
       "0               124.687808          124.687808           117.753249   \n",
       "1               125.901900          125.901900           119.170554   \n",
       "2               125.525454          125.525454           120.885401   \n",
       "3               125.352400          125.352400           120.464476   \n",
       "4               124.336604          124.336604           119.684258   \n",
       "...                    ...                 ...                  ...   \n",
       "135605         -119.294532         -119.294532          -109.548147   \n",
       "135606         -116.781227         -116.781227          -111.486480   \n",
       "135607         -115.371234         -115.371234          -112.017345   \n",
       "135608         -112.702916         -112.702916          -111.178383   \n",
       "135609         -118.268117         -118.268117          -111.726932   \n",
       "\n",
       "        right_ankle_angle_2  hip_x_diff  hip_y_diff  ...  heel_depth_diff  \\\n",
       "0                178.871808   -0.022037   -0.010157  ...        -0.209389   \n",
       "1                178.859718   -0.021962   -0.010169  ...        -0.209575   \n",
       "2                179.617597   -0.021918   -0.010162  ...        -0.210042   \n",
       "3                179.698710   -0.021915   -0.010131  ...        -0.209887   \n",
       "4                179.568240   -0.021736   -0.010054  ...        -0.209237   \n",
       "...                     ...         ...         ...  ...              ...   \n",
       "135605          -169.571432   -0.091402    0.005945  ...         0.241113   \n",
       "135606          -169.417255   -0.090995    0.006019  ...         0.245908   \n",
       "135607          -171.917360   -0.079152    0.006154  ...         0.248112   \n",
       "135608          -171.181592   -0.077574    0.006344  ...         0.240782   \n",
       "135609          -170.416124   -0.072327    0.006402  ...         0.249770   \n",
       "\n",
       "        footindex_x_diff  footindex_y_diff  footindex_depth_diff  hip_length  \\\n",
       "0              -0.005688          0.002777             -0.246590    0.024265   \n",
       "1              -0.010760          0.003125             -0.246531    0.024202   \n",
       "2              -0.014307          0.003023             -0.247234    0.024160   \n",
       "3              -0.013344          0.004727             -0.247226    0.024143   \n",
       "4              -0.011709          0.004902             -0.247245    0.023949   \n",
       "...                  ...               ...                   ...         ...   \n",
       "135605         -0.046102          0.025827              0.265046    0.091595   \n",
       "135606         -0.024700          0.020011              0.271999    0.091194   \n",
       "135607          0.031073          0.021912              0.273472    0.079391   \n",
       "135608          0.028780          0.022070              0.266361    0.077833   \n",
       "135609          0.109860          0.021170              0.275109    0.072610   \n",
       "\n",
       "        knee_length  ankle_length  heel_length  footindex_length  class  \n",
       "0          0.029204      0.031500     0.028015          0.006329      0  \n",
       "1          0.029707      0.031654     0.029309          0.011205      0  \n",
       "2          0.029508      0.031547     0.028907          0.014623      0  \n",
       "3          0.029883      0.033603     0.030935          0.014157      0  \n",
       "4          0.030548      0.034196     0.030836          0.012693      0  \n",
       "...             ...           ...          ...               ...    ...  \n",
       "135605     0.009056      0.016802     0.024268          0.052844      6  \n",
       "135606     0.007935      0.008990     0.012116          0.031789      6  \n",
       "135607     0.030440      0.053772     0.049270          0.038022      6  \n",
       "135608     0.031844      0.049678     0.045033          0.036268      6  \n",
       "135609     0.063430      0.127003     0.125666          0.111881      6  \n",
       "\n",
       "[135610 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_hip_anlge          9\n",
       "right_hip_anlge         9\n",
       "left_knee_anlge         9\n",
       "right_knee_anlge        9\n",
       "left_ankle_angle_1      9\n",
       "left_ankle_angle_2      9\n",
       "right_ankle_angle_1     9\n",
       "right_ankle_angle_2     9\n",
       "hip_x_diff              9\n",
       "hip_y_diff              9\n",
       "hip_depth_diff          9\n",
       "knee_x_diff             9\n",
       "knee_y_diff             9\n",
       "knee_depth_diff         9\n",
       "ankle_x_diff            9\n",
       "ankle_y_diff            9\n",
       "ankle_depth_diff        9\n",
       "heel_x_diff             9\n",
       "heel_y_diff             9\n",
       "heel_depth_diff         9\n",
       "footindex_x_diff        9\n",
       "footindex_y_diff        9\n",
       "footindex_depth_diff    9\n",
       "hip_length              9\n",
       "knee_length             9\n",
       "ankle_length            9\n",
       "heel_length             9\n",
       "footindex_length        9\n",
       "class                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_hip_anlge          0\n",
       "right_hip_anlge         0\n",
       "left_knee_anlge         0\n",
       "right_knee_anlge        0\n",
       "left_ankle_angle_1      0\n",
       "left_ankle_angle_2      0\n",
       "right_ankle_angle_1     0\n",
       "right_ankle_angle_2     0\n",
       "hip_x_diff              0\n",
       "hip_y_diff              0\n",
       "hip_depth_diff          0\n",
       "knee_x_diff             0\n",
       "knee_y_diff             0\n",
       "knee_depth_diff         0\n",
       "ankle_x_diff            0\n",
       "ankle_y_diff            0\n",
       "ankle_depth_diff        0\n",
       "heel_x_diff             0\n",
       "heel_y_diff             0\n",
       "heel_depth_diff         0\n",
       "footindex_x_diff        0\n",
       "footindex_y_diff        0\n",
       "footindex_depth_diff    0\n",
       "hip_length              0\n",
       "knee_length             0\n",
       "ankle_length            0\n",
       "heel_length             0\n",
       "footindex_length        0\n",
       "class                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135601, 28)\n",
      "(135601,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, :-1]\n",
    "Y = dataset.iloc[:, 28]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       left_hip_anlge  right_hip_anlge  left_knee_anlge  right_knee_anlge  \\\n",
      "count   135601.000000    135601.000000    135601.000000     135601.000000   \n",
      "mean       -39.495104        45.398594        68.788956        -15.788586   \n",
      "std        158.272664       156.339430       150.443785        164.873780   \n",
      "min       -179.999801      -179.999816      -179.999763       -179.998260   \n",
      "25%       -168.987345      -160.770949      -157.223550       -167.606439   \n",
      "50%       -153.843056       149.301475       157.673465       -151.622632   \n",
      "75%        160.168875       170.907532       170.387335        167.578439   \n",
      "max        179.999614       179.999602       179.999898        179.999868   \n",
      "\n",
      "       left_ankle_angle_1  left_ankle_angle_2  right_ankle_angle_1  \\\n",
      "count       135601.000000       135601.000000        135601.000000   \n",
      "mean            18.832092           18.832092            16.443020   \n",
      "std            117.092874          117.092874           120.323593   \n",
      "min           -179.940152         -179.940152          -179.983047   \n",
      "25%           -110.298197         -110.298197          -113.584250   \n",
      "50%            114.046421          114.046421           112.981171   \n",
      "75%            121.363575          121.363575           123.671873   \n",
      "max            179.828248          179.828248           179.925306   \n",
      "\n",
      "       right_ankle_angle_2     hip_x_diff     hip_y_diff  ...    heel_y_diff  \\\n",
      "count        135601.000000  135601.000000  135601.000000  ...  135601.000000   \n",
      "mean            -11.585994      -0.055123      -0.002291  ...       0.008048   \n",
      "std             172.472360       0.056502       0.023410  ...       0.071624   \n",
      "min            -179.999751      -0.229854      -0.138288  ...      -0.631617   \n",
      "25%            -169.104006      -0.088714      -0.015084  ...      -0.023011   \n",
      "50%            -163.869671      -0.054704      -0.003116  ...       0.005013   \n",
      "75%             176.155327      -0.020369       0.010195  ...       0.033864   \n",
      "max             179.999116       0.154060       0.122711  ...       0.649918   \n",
      "\n",
      "       heel_depth_diff  footindex_x_diff  footindex_y_diff  \\\n",
      "count    135601.000000     135601.000000     135601.000000   \n",
      "mean         -0.007515         -0.018378          0.011357   \n",
      "std           0.232384          0.248010          0.074996   \n",
      "min          -0.745405         -1.053912         -0.742094   \n",
      "25%          -0.202304         -0.158007         -0.018102   \n",
      "50%          -0.116076         -0.014731          0.004630   \n",
      "75%           0.221132          0.106787          0.037530   \n",
      "max           0.697869          0.954011          0.702980   \n",
      "\n",
      "       footindex_depth_diff     hip_length    knee_length   ankle_length  \\\n",
      "count         135601.000000  135601.000000  135601.000000  135601.000000   \n",
      "mean              -0.016387       0.068512       0.101186       0.165942   \n",
      "std                0.265560       0.045720       0.080810       0.150010   \n",
      "min               -0.825358       0.000107       0.000116       0.000069   \n",
      "25%               -0.242064       0.031067       0.037963       0.040877   \n",
      "50%               -0.143062       0.061352       0.074897       0.123174   \n",
      "75%                0.246188       0.095218       0.148331       0.251909   \n",
      "max                0.745569       0.234621       0.511680       0.931672   \n",
      "\n",
      "         heel_length  footindex_length  \n",
      "count  135601.000000     135601.000000  \n",
      "mean        0.174843          0.191528  \n",
      "std         0.159040          0.175831  \n",
      "min         0.000142          0.000049  \n",
      "25%         0.041470          0.041058  \n",
      "50%         0.130827          0.143412  \n",
      "75%         0.267534          0.298342  \n",
      "max         0.985512          1.055912  \n",
      "\n",
      "[8 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "0    39096\n",
      "1    10189\n",
      "2    10251\n",
      "3    13863\n",
      "4    10418\n",
      "5    11996\n",
      "6    39788\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.groupby(Y).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.values\n",
    "#y_train = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    # input_dim 개수는 features 개수, 근데 unit의 수를 feature 개수라 한 자료도 있음. -> 아직 잘 모르겠음\n",
    "    model.add(Dense(15, input_dim = 28, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "    model.add(Dense(15, activation = 'relu'))\n",
    "    model.add(Dense(7, activation = 'softmax')) # Softmax for multi-class classification\n",
    "    # Compile model here\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn = baseline_model, epochs = 100, batch_size = 10, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d29d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d29d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc486071ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc486071ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc487e13e18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc487e13e18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc48a43e9d8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc48a43e9d8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc48a178ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc48a178ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4860aa950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4860aa950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4783c2bf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4783c2bf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4783e2158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc4783e2158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc48a43e488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc48a43e488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc484d257b8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc484d257b8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X_train, y_train, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d25c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d25c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a3dd6840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a3dd6840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4850d10d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4850d10d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d0cae8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484d0cae8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n",
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a3dd6840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a3dd6840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 1494, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 767, in fit\n",
      "    **kwargs,\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "    **kwargs,\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n",
      "    target.shape.assert_is_compatible_with(output.shape)\n",
      "ValueError: Shapes (10, 1) and (10, 7) are incompatible\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 1494, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 767, in fit\n",
      "    **kwargs,\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "    **kwargs,\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n",
      "    target.shape.assert_is_compatible_with(output.shape)\n",
      "ValueError: Shapes (None, 1) and (None, 7) are incompatible\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X, Y, cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 77.00% (1.30%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Result: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bb8/opt/anaconda3/envs/tens/lib/python3.7/site-packages/scikeras/wrappers.py:302: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484f02730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc484f02730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장\n",
    "estimator.save(\"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 불러오기\n",
    "import keras\n",
    "reconstructed_model = keras.models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=7)\n",
    "#y_test = tf.keras.utils.to_categorical(y_test, num_classes=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108480, 28) (108480,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'describe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-bec2ed01d95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'describe'"
     ]
    }
   ],
   "source": [
    "X_train.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=28, input_dim = X_train.shape[1], activation='relu'),\n",
    "    tf.keras.layers.Dense(units=14, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-47dfd6cafb4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07),\n\u001b[1;32m      2\u001b[0m             loss='binary_crossentropy', metrics=['accuracy'])\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2870\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2871\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m           'the model on a batch of data.')\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07),\n",
    "            loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a2c87840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4a2c87840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`logits` and `labels` must have the same shape, received ((None, 7) vs (None, 1)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-18380ce07a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tens/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m   5281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5282\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5285\u001b[0m   if (not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable)) and\n",
      "\u001b[0;31mValueError\u001b[0m: `logits` and `labels` must have the same shape, received ((None, 7) vs (None, 1))."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=25, batch_size=32, validation_split=0.25, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tens')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9805838b4ba203dcba0674bac8b279717a6e59177d23b2f0adf4ed7cf39b318e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
